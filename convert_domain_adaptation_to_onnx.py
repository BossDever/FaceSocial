import torch
import torch.nn as nn
import timm
import os
import numpy as np

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå
INPUT_PATH = '/mnt/d/FaceSocial/models/deepfake/domain_adapt_models/domain_adaptation_model.pth'
OUTPUT_DIR = '/mnt/d/FaceSocial/models/deepfake/domain_adapt_models_onnx'
os.makedirs(OUTPUT_DIR, exist_ok=True)
OUTPUT_PATH = os.path.join(OUTPUT_DIR, 'domain_adaptation_model.onnx')

print(f"üìÇ ‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡πâ‡∏ô‡∏ó‡∏≤‡∏á: {INPUT_PATH}")
print(f"üìÇ ‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏õ‡∏•‡∏≤‡∏¢‡∏ó‡∏≤‡∏á: {OUTPUT_PATH}")

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
if not os.path.exists(INPUT_PATH):
    print(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡πâ‡∏ô‡∏ó‡∏≤‡∏á: {INPUT_PATH}")
    exit(1)
else:
    print(f"‚úÖ ‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡πâ‡∏ô‡∏ó‡∏≤‡∏á")

# ‡∏Ñ‡∏•‡∏≤‡∏™ Gradient Reversal Layer
class GradientReversalLayer(torch.autograd.Function):
    @staticmethod
    def forward(ctx, x, alpha):
        ctx.alpha = alpha
        return x.view_as(x)
    
    @staticmethod
    def backward(ctx, grad_output):
        output = grad_output.neg() * ctx.alpha
        return output, None

# ‡∏Ñ‡∏•‡∏≤‡∏™‡πÇ‡∏°‡πÄ‡∏î‡∏• Domain Adaptation
class DomainAdaptationModel(nn.Module):
    def __init__(self, model_name='tf_efficientnet_b4'):
        super().__init__()
        # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
        self.base_model = timm.create_model(model_name, pretrained=False)
        
        # ‡∏´‡∏≤‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡∏≠‡∏á feature
        n_features = self.base_model.classifier.in_features
        self.base_model.classifier = nn.Identity()
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á classifier ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏≥‡πÅ‡∏ô‡∏Å real/fake
        self.classifier = nn.Linear(n_features, 1)
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á domain classifier ‡∏û‡∏£‡πâ‡∏≠‡∏° gradient reversal
        self.domain_classifier = nn.Sequential(
            nn.Linear(n_features, 256),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(256, 1)
        )
    
    def forward(self, x, alpha=1.0):
        # ‡∏™‡∏Å‡∏±‡∏î features
        features = self.base_model(x)
        
        # ‡∏™‡πà‡∏á‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏¢‡∏±‡∏á classifier ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏≥‡πÅ‡∏ô‡∏Å real/fake
        class_output = self.classifier(features)
        
        # ONNX ‡πÑ‡∏°‡πà‡∏™‡∏ô‡∏±‡∏ö‡∏™‡∏ô‡∏∏‡∏ô GradientReversalLayer ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á ‡πÉ‡∏ô‡πÇ‡∏´‡∏°‡∏î inference ‡πÄ‡∏£‡∏≤‡πÅ‡∏Ñ‡πà‡∏™‡πà‡∏á‡∏Ñ‡πà‡∏≤ features ‡πÑ‡∏õ
        # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö inference ‡πÄ‡∏£‡∏≤‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ gradient reversal
        domain_output = self.domain_classifier(features)
        
        return class_output, domain_output

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•
def convert_domain_adaptation_model_to_onnx():
    # ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡πÉ‡∏ä‡πâ CPU
    device = torch.device('cpu')
    model = DomainAdaptationModel()
    
    # ‡πÇ‡∏´‡∏•‡∏î state_dict ‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏´‡∏°‡∏î‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•
    try:
        state_dict = torch.load(INPUT_PATH, map_location=device)
        model.load_state_dict(state_dict, strict=False)
        print("‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
    except Exception as e:
        print(f"‚ö†Ô∏è ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏î‡πâ‡πÅ‡∏ï‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô: {str(e)}")
    
    # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏´‡∏°‡∏î‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•
    model.eval()
    # ‡∏¢‡πâ‡∏≤‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏õ CPU ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
    model = model.to(device)
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á dummy input ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á
    dummy_input = torch.randn(1, 3, 224, 224, device=device)
    alpha = torch.tensor(1.0)
    
    # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö ONNX
    dynamic_axes = {
        'input': {0: 'batch_size'},
        'class_output': {0: 'batch_size'},
        'domain_output': {0: 'batch_size'}
    }
    
    # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô ONNX
    try:
        torch.onnx.export(
            model,                      # ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á
            (dummy_input, alpha),       # ‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á (x, alpha)
            OUTPUT_PATH,                # ‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏≠‡∏≤‡∏ï‡πå‡∏û‡∏∏‡∏ï
            export_params=True,         # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡πà‡∏≤‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå ONNX
            opset_version=12,           # ‡∏£‡∏∏‡πà‡∏ô ONNX
            do_constant_folding=True,   # ‡πÇ‡∏ü‡∏•‡∏î‡πå‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡πÄ‡∏ß‡∏•‡∏≤‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì
            input_names=['input', 'alpha'],  # ‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï
            output_names=[              # ‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏≠‡∏≤‡∏ï‡πå‡∏û‡∏∏‡∏ï
                'class_output',
                'domain_output'
            ],
            dynamic_axes=dynamic_axes    # ‡πÅ‡∏Å‡∏ô‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡πÑ‡∏î‡πâ (batch size)
        )
        print(f"‚úÖ ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô ONNX ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {OUTPUT_PATH}")
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡πÑ‡∏ü‡∏•‡πå
        onnx_size = os.path.getsize(OUTPUT_PATH) / (1024 * 1024)  # MB
        print(f"üìä ‡∏Ç‡∏ô‡∏≤‡∏î‡πÑ‡∏ü‡∏•‡πå ONNX: {onnx_size:.2f} MB")
        
        return True
    except Exception as e:
        print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô ONNX: {str(e)}")
        return False

if __name__ == "__main__":
    convert_domain_adaptation_model_to_onnx()